[{"kind":1,"language":"markdown","value":"## üè° Operation Next Nest | Part 2 (SAS + Optimization)\n\nWelcome back to **Operation Next Nest**!\n\nIn **Part 1 (Python)**, we:\n- Pulled block-group level ACS data for Wake & Durham Counties\n- Added:\n  - Demographics + housing + income variables\n  - Distance and estimated travel time to the SAS campus\n  - Amenity flags from OpenStreetMap:\n    - `has_grocery_store`\n    - `has_park`\n    - `has_bike_trail`\n- Exported a flat file called **`operation_next_nest.csv`** for SAS\n\nIn **Part 2 (SAS)**, we will:\n1. Import the `operation_next_nest` data into SAS\n2. Prepare variables for optimization (e.g., commute, kid-friendliness, cost, amenities)\n3. Build a **composite neighborhood score** using weights\n4. Use `PROC OPTMODEL` to:\n   - Select the \"best\" neighborhoods subject to constraints:\n     - Max commute time (e.g., 30 minutes)\n     - Max median housing value\n   - Run different *preference scenarios* by changing the weights\n\nThink of this notebook as the **‚Äúdecision engine‚Äù** for the Next Nest search.\n","outputs":[]},{"kind":2,"language":"sas","value":"/* 1. Point SAS to the folder with the CSV from Python */\n%let proj_root = /workspaces/myfolder/OperationNextNest;\n%let data_path = &proj_root./Data;\n\nlibname nest \"&data_path.\";\n\n/* 2. Import the CSV created in Part 1 */\nproc import datafile=\"&data_path./operation_next_nest.csv\"\n    out=operation_next_nest_raw\n    dbms=csv\n    replace;\n    guessingrows=max;\nrun;\n\n/* 3. Take a peek at structure */\nproc contents data=operation_next_nest_raw order=varnum; run;\n\nproc print data=operation_next_nest_raw(obs=5); run;\n","outputs":[]},{"kind":1,"language":"markdown","value":"### üßπ Step 2 ‚Äî Clean Up Variable Names & Create an ID\n\nThe CSV we imported has SAS-friendly variable names (32 characters, underscores, etc.).\n\nIn this step we:\n\n1. Create **short, readable aliases** for the main variables we‚Äôll use in optimization:\n   - `travel_time_min`     ‚Üí commute in minutes\n   - `distance_miles`      ‚Üí straight-line distance to SAS\n   - `median_value`        ‚Üí median housing value\n   - `median_income`       ‚Üí median household income\n   - `pct_kids_under6`     ‚Üí % households with young kids\n   - `has_grocery`, `has_park`, `has_bike` ‚Üí amenity flags\n2. Add a simple integer ID variable `bg_id` for each block group\n3. (Optionally) Filter out rows with missing key fields\n","outputs":[]},{"kind":2,"language":"sas","value":"data operation_next_nest_prep;\n    set operation_next_nest_raw;\n\n    /* Commute and distance */\n    travel_time_min = Travel_Time_to_Office__minutes_;   /* e.g., from \"Travel_Time_to_Office__minutes_\" */\n    distance_miles  = Distance_to_Office__miles_;        /* e.g., from \"Distance_to_Office__miles_\" */\n\n    /* Housing + income */\n    median_value    = Median_Housing_Value;\n    median_income   = Median_Household_Income;\n\n    /* Kid-friendliness (percent households with kids under 6) */\n    pct_kids_under6 = __Households_with_Children_under; \n    \n    /* Amenities */\n    has_grocery     = has_grocery_store;\n    has_park_flag   = has_park;\n    has_bike_flag   = has_bike_trail;\n\n    /* Simple 0/1 amenity count for later scoring */\n    amenity_count = sum(has_grocery, has_park_flag, has_bike_flag);\n\n    /* Add a numeric ID for optimization index */\n    bg_id = _n_;\nrun;\n\n/* Quick check */\nproc means data=operation_next_nest_prep n nmiss min p25 median p75 max;\n    var travel_time_min distance_miles median_value median_income pct_kids_under6 amenity_count;\nrun;\n","outputs":[]},{"kind":1,"language":"markdown","value":"### ‚è±Ô∏è Step 3 ‚Äî Basic Filters and 0‚Äì1 Standardization\n\nBefore we optimize, we‚Äôll:\n\n1. Keep only block groups with a *reasonable* maximum travel time \n   (e.g., ‚â§ 45 minutes, a loose upper bound).\n2. Standardize key numeric variables to a **0‚Äì1 scale**:\n   - Lower commute time ‚Üí higher commute score\n   - Lower housing value ‚Üí higher affordability score\n   - Higher median income ‚Üí higher income score\n   - Higher % kids under 6 ‚Üí higher kid-friendliness score\n3. Compute a simple amenity score based on how many of our 3 amenity flags are present.\n\nThis gives us a clean, comparable set of scores for optimization and ranking.\n","outputs":[]},{"kind":2,"language":"sas","value":"/* 3a. Filter to remove truly extreme commutes (e.g., >45 minutes or missing) */\ndata onn_filtered;\n    set operation_next_nest_prep;\n\n    /* Required optimization inputs must be present */\n    if missing(travel_time_min) then delete;\n    if missing(median_value) then delete;\n    if missing(median_income) then delete;\n    if missing(pct_kids_under6) then delete;\n\n    /* Simple commute sanity filter */\n    if travel_time_min > 45 then delete;\n\n    /* Other Missing values */\n    if median_value     <= 0 then delete ;\n    if travel_time_min  <= 0 then delete ;\nrun;\n\n/* 3b. Standardize selected variables to 0‚Äì1 range */\nproc stdize data=onn_filtered\n            out=onn_std\n            method=range;\n    var travel_time_min\n        distance_miles\n        median_value\n        median_income\n        pct_kids_under6\n        amenity_count;\nrun;\n\n/* 3c. Direction-corrected scores: higher is better for all */\ndata onn_scores;\n    set onn_std;\n\n    /* commuting: lower time/distance is better */\n    commute_score = 1 - travel_time_min; /* now 0=worst (long commute), 1=best */\n\n    /* affordability: lower median value is better */\n    housing_afford_score = 1 - median_value;\n\n    /* income: higher is better */\n    income_score = median_income;\n\n    /* kid-friendliness: higher % kids under 6 is better */\n    kids_score = pct_kids_under6;\n\n    /* amenities: more is better */\n    amenity_score = amenity_count;\n\n    /* Keep ID and GEOID in the scoring dataset */\n    keep bg_id GEOID commute_score housing_afford_score income_score\n         kids_score amenity_score travel_time_min distance_miles median_value median_income;\nrun;\n\nproc print data=onn_scores(obs=5); run;\n","outputs":[]},{"kind":1,"language":"markdown","value":"### ‚öñÔ∏è Step 4 | Run Optimization Scenarios with PROC OPTMODEL\n\nIn this step we wrap our optimization logic in a macro called `RUN_SCENARIO`.\n\nFor each scenario, we will:\n\n1. Start from the standardized scores in `onn_scores`\n2. Apply a set of **weights** to build a `weighted_score`:\n   - `w_commute`   ‚Üí importance of short commute\n   - `w_kids`      ‚Üí importance of kid-friendliness\n   - `w_housing`   ‚Üí importance of affordability\n   - `w_income`    ‚Üí importance of higher-income neighborhoods\n   - `w_amenities` ‚Üí importance of having parks/groceries/bike trails\n3. Use `PROC OPTMODEL` to:\n   - Maximize the total weighted score\n   - Choose a fixed number of neighborhoods (`n_choice`)\n   - Enforce constraints on:\n     - max commute time (`max_travel`)\n     - max median housing value (`max_value`)\n4. Write out the **chosen neighborhoods** into a scenario-specific table.\n\nThis lets us easily run multiple ‚Äúwhat if‚Äù scenarios by changing only the macro parameters.\n","outputs":[]},{"kind":2,"language":"sas","value":"%macro run_scenario( scen_name, n_choice, max_travel, max_value, w_commute, w_kids, w_housing, w_income, w_amenities );\n\n    %put NOTE: ===== Running Operation Next Nest scenario &=scen_name =====;\n\n    /* 4a. Compute weighted score for this scenario */\n    data onn_scores_&scen_name.;\n        set onn_scores;\n\n        weighted_score =\n              &w_commute   * commute_score\n            + &w_kids      * kids_score\n            + &w_housing   * housing_afford_score\n            + &w_income    * income_score\n            + &w_amenities * amenity_score;\n    run;\n\n    /* 4b. Optimization with PROC OPTMODEL */\n    proc optmodel;\n        /* Set of block groups (indexed by bg_id) */\n        set BG;\n        num score{BG};\n        num travel{BG};\n        num value{BG};\n\n        /* Read scenario-specific data into OPTMODEL */\n        read data onn_scores_&scen_name.\n            into BG=[bg_id]\n                 score=weighted_score\n                 travel=travel_time_min\n                 value=median_value;\n\n        /* Decision variable: x[i] = 1 if we select block group i */\n        var x{BG} binary;\n\n        /* Objective: maximize total weighted score */\n        max TotalScore = sum{i in BG} score[i] * x[i];\n\n        /* Constraint: choose exactly n_choice neighborhoods */\n        con ChooseLimit: sum{i in BG} x[i] = &n_choice.;\n\n        /* Constraint: max travel time for any chosen neighborhood */\n        con TravelLimit{i in BG}: travel[i] * x[i] <= &max_travel.;\n\n        /* Constraint: max median housing value for any chosen neighborhood */\n        con ValueLimit{i in BG}: value[i] * x[i] <= &max_value.;\n\n        /* Solve as a MILP */\n        solve with milp;\n\n        /* 4c. Create a dataset with chosen neighborhoods only\n           NOTE: This uses the documented \"create data ... from [index] = {iterators}\" syntax. */\n        create data onn_choice_&scen_name. from\n            [bg_id] = {i in BG: x[i] > 0.5}\n            x       = x[i]\n            score   = score[i]\n            travel  = travel[i]\n            value   = value[i]\n        ;\n    quit;\n\n    /* 4d. Join back to the full scored table for readable output */\n    proc sql;\n        create table onn_result_&scen_name. as\n        select  a.*,\n                b.x       as chosen_flag,\n                b.score   as optmodel_score,\n                b.travel  as optmodel_travel,\n                b.value   as optmodel_value\n        from onn_scores_&scen_name. as a\n        left join onn_choice_&scen_name. as b\n        on a.bg_id = b.bg_id\n        order by weighted_score desc;\n    quit;\n\n    title \"Operation Next Nest - Scenario &scen_name (Chosen Neighborhoods)\";\n    proc print data=onn_result_&scen_name.(where=(chosen_flag=1)) noobs;\n        var bg_id GEOID weighted_score travel_time_min median_value median_income;\n    run;\n    title;\n\n********************************************  Export Data to .CSV to retain formatting;\n    proc export data=onn_result_&scen_name.\n        outfile=\"&data_path./onn_result_&scen_name..csv\"\n        dbms=csv\n        replace;\n    run;\n\n\n%mend run_scenario;\n\n**************************************  Run Base Scenario;\n%run_scenario(\n    scen_name=Base,\n    n_choice=10,\n    max_travel=30,\n    max_value=800000,\n    w_commute=0.25,\n    w_kids=0.25,\n    w_housing=0.20,\n    w_income=0.10,\n    w_amenities=0.20 );\n","outputs":[]},{"kind":1,"language":"markdown","value":"### üß™ Step 5 | Run a Few ‚ÄúWhat If‚Äù Scenarios\n\nNow for the fun part: changing the weights!\n\nTry a few different preference profiles:\n\n1. **Commute-First** ‚Äî shortest drive wins  \n2. **Kid-Friendly** ‚Äî prioritize young families  \n3. **Amenity-Lover** ‚Äî parks, groceries, bikes\n\nEach call below runs the optimization with a different weighting scheme.\n","outputs":[]},{"kind":2,"language":"sas","value":"/* 5.1 Commute-first (heavy commute weight, tighter travel cap) */\n%run_scenario(\n    scen_name=CommuteFirst,\n    n_choice=10,\n    max_travel=25,\n    max_value=900000,\n    w_commute=0.45,\n    w_kids=0.20,\n    w_housing=0.15,\n    w_income=0.10,\n    w_amenities=0.10\n);\n\n/* 5.2 Kid-friendly focus (high weight on pct kids) */\n%run_scenario(\n    scen_name=KidFriendly,\n    n_choice=10,\n    max_travel=30,\n    max_value=900000,\n    w_commute=0.20,\n    w_kids=0.40,\n    w_housing=0.15,\n    w_income=0.10,\n    w_amenities=0.15\n);\n\n/* 5.3 Amenity-lover (parks/groceries/bike trails matter most) */\n%run_scenario(\n    scen_name=AmenityHeavy,\n    n_choice=10,\n    max_travel=30,\n    max_value=900000,\n    w_commute=0.20,\n    w_kids=0.20,\n    w_housing=0.15,\n    w_income=0.10,\n    w_amenities=0.35\n);\n","outputs":[]}]